{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class  ANN_perceptron:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def sigmoid(self, Z):      \n",
    "        A = 1/(1+np.exp(-Z))       \n",
    "        return A\n",
    "    \n",
    "    def softmax(self, Z):\n",
    "        expZ = np.exp(Z - np.max(Z))\n",
    "        return expZ / expZ.sum(axis=0, keepdims=True)\n",
    "    \n",
    "    def relu(self, Z):\n",
    "        A = np.maximum(0,Z)\n",
    "        cache = Z \n",
    "        return A\n",
    "\n",
    "    def deep_initialize_parameters(self, layer_dims):\n",
    "        np.random.seed(1)\n",
    "        parameters = {}\n",
    "        L = len(layer_dims)            # number of layers in the network\n",
    "\n",
    "        for l in range(1, L):\n",
    "            parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1])/np.sqrt(layer_dims[l-1])# *0.01\n",
    "            parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "        return parameters\n",
    "\n",
    "    def linear_activation_forward(self,A_prev, W, b, activation):\n",
    "        Z = np.dot(W,A_prev) + b\n",
    "        linear_cache = (A_prev, W, b)\n",
    "\n",
    "        if activation == \"softmax\":    \n",
    "            A = self.softmax(Z)\n",
    "        elif activation == \"relu\":\n",
    "            A = self.relu(Z)\n",
    "\n",
    "        cache = (linear_cache, Z)\n",
    "        return A, cache\n",
    "\n",
    "    \n",
    "    def deep_model_forward(self,X, parameters):\n",
    "        caches = []\n",
    "        A = X\n",
    "        L = len(parameters) // 2  \n",
    "        for l in range(1, L):\n",
    "            A_prev = A \n",
    "            A, cache = self.linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], activation = \"relu\")\n",
    "            caches.append(cache)\n",
    "\n",
    "        AL, cache = self.linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], activation = \"softmax\")\n",
    "        caches.append(cache)\n",
    "        return AL, caches\n",
    "\n",
    "    def compute_cost(self,AL, Y):\n",
    "        m = Y.shape[1]\n",
    "        cost = (-1/m)*np.sum(Y * np.log(AL))\n",
    "        cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
    "        assert(cost.shape == ())\n",
    "        return cost\n",
    "\n",
    "    def linear_backward(self,dZ, cache):\n",
    "        A_prev, W, b = cache\n",
    "        m = A_prev.shape[1]\n",
    "\n",
    "        dW = 1./m * np.dot(dZ,A_prev.T)\n",
    "        db = 1./m * np.sum(dZ, axis = 1, keepdims = True)\n",
    "        dA_prev = np.dot(W.T,dZ)\n",
    "        return dA_prev, dW, db    \n",
    "\n",
    "    def relu_backward(self,dA, cache):\n",
    "        Z = cache\n",
    "        dZ = np.array(dA, copy=True)\n",
    "        dZ[Z <= 0] = 0\n",
    "        assert (dZ.shape == Z.shape)\n",
    "        return dZ\n",
    "    \n",
    "    def sigmoid_backward(self, dA, cache):\n",
    "        Z = cache    \n",
    "        s = 1/(1+np.exp(-Z))\n",
    "        dZ = dA * s * (1-s)\n",
    "        assert (dZ.shape == Z.shape)    \n",
    "        return dZ\n",
    "\n",
    "    def softmax_backward(self,AL,Y,cache):\n",
    "        Z = cache\n",
    "        dZ = AL - Y\n",
    "        assert (dZ.shape == Z.shape)\n",
    "        return dZ \n",
    "    \n",
    "    def linear_activation_backward(self,Y,AL,dA, cache, activation):\n",
    "        linear_cache, activation_cache = cache\n",
    "        if activation == \"softmax\":\n",
    "            dZ = self.softmax_backward(AL,Y,activation_cache)\n",
    "            dA_prev, dW, db = self.linear_backward(dZ, linear_cache)\n",
    "\n",
    "        elif activation == \"relu\":\n",
    "            dZ = self.relu_backward(dA, activation_cache)\n",
    "            dA_prev, dW, db = self.linear_backward(dZ, linear_cache)\n",
    "\n",
    "        return dA_prev, dW, db\n",
    "\n",
    "\n",
    "    def deep_model_backward(self,AL, Y, caches):\n",
    "        grads = {}\n",
    "        L = len(caches) # the number of layers\n",
    "        m = AL.shape[1]\n",
    "        Y = Y.reshape(AL.shape)\n",
    "\n",
    "        dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "\n",
    "        current_cache = caches[L-1]\n",
    "        grads[\"dA\" + str(L)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = self.linear_activation_backward(Y,AL,dAL, current_cache, activation = \"softmax\")\n",
    "        for l in reversed(range(L-1)):\n",
    "            current_cache = caches[l]\n",
    "            dA_prev_temp, dW_temp, db_temp = self.linear_activation_backward(Y,AL,grads[\"dA\" + str(l + 2)], current_cache, activation = \"relu\")\n",
    "            grads[\"dA\" + str(l + 1)] = dA_prev_temp\n",
    "            grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "            grads[\"db\" + str(l + 1)] = db_temp\n",
    "\n",
    "        return grads\n",
    " \n",
    "\n",
    "    def update_parameters(self,parameters, grads, learning_rate):\n",
    "        L = len(parameters) // 2\n",
    "        for l in range(L):\n",
    "            parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n",
    "            parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]\n",
    "\n",
    "        return parameters\n",
    "\n",
    "    def deep_layer_model(self,X, Y, layers_dims, learning_rate, num_iterations): #lr was 0.009\n",
    "        costs = []\n",
    "        parameters = self.deep_initialize_parameters(layers_dims)\n",
    "        for i in range(0, num_iterations):\n",
    "            AL, caches = self.deep_model_forward(X, parameters)\n",
    "            cost = self.compute_cost(AL, Y)\n",
    "            grads = self.deep_model_backward(AL, Y, caches)\n",
    "            parameters = self.update_parameters(parameters, grads, learning_rate)\n",
    "            costs.append(cost)\n",
    "            if i % 100 == 0:\n",
    "                print (\"Cost after iteration %i: %f\" % (i, cost))\n",
    "        return parameters, costs\n",
    "    \n",
    "    def predict(self,params, X, Y):\n",
    "        probs, caches = self.deep_model_forward(X, params) \n",
    "        y_hat = np.argmax(probs, axis=0)\n",
    "        Y = np.argmax(Y, axis=0)\n",
    "        conf_matrix=self.compute_confusion_matrix(Y, y_hat)\n",
    "        print(\"label precision recall\")\n",
    "        for label in range(5):\n",
    "            print(f\"{label:5d} {self.precision(label, conf_matrix):9.3f} {self.recall(label, conf_matrix):6.3f}\")\n",
    "\n",
    "        accuracy = self.accuracy(conf_matrix)\n",
    "        print(\"Test Accuracy: \",accuracy)        \n",
    "        return conf_matrix\n",
    "    \n",
    "    def compute_confusion_matrix(self,true, pred):\n",
    "        K = len(np.unique(true)) # Number of classes \n",
    "        result = np.zeros((K, K))\n",
    "        for i in range(len(true)):\n",
    "            result[true[i]][pred[i]] += 1\n",
    "        return result\n",
    "\n",
    "    def precision(self,label, confusion_matrix):\n",
    "        col = confusion_matrix[:, label]\n",
    "        return confusion_matrix[label, label] / col.sum()\n",
    "\n",
    "    def recall(self,label, confusion_matrix):\n",
    "        row = confusion_matrix[label, :]\n",
    "        return confusion_matrix[label, label] / row.sum()\n",
    "    \n",
    "    def accuracy(self,confusion_matrix):\n",
    "        diagonal_sum = confusion_matrix.trace()\n",
    "        sum_of_all_elements = confusion_matrix.sum()\n",
    "        return diagonal_sum / sum_of_all_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "    x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "    x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "    X_TRAIN=[]\n",
    "    Y_TRAIN=[]\n",
    "    for i in range(len(y_train)):\n",
    "        if y_train[i]<5:\n",
    "            X_TRAIN.append(x_train[i])\n",
    "            Y_TRAIN.append(y_train[i])\n",
    "\n",
    "    X_TEST=[]\n",
    "    Y_TEST=[]\n",
    "    for i in range(len(y_test)):\n",
    "        if y_test[i]<5:\n",
    "            X_TEST.append(x_test[i])\n",
    "            Y_TEST.append(y_test[i])\n",
    "\n",
    "    X_TRAIN=np.array(X_TRAIN)\n",
    "    Y_TRAIN=np.array(Y_TRAIN)\n",
    "\n",
    "    X_TEST=np.array(X_TEST)\n",
    "    Y_TEST=np.array(Y_TEST)\n",
    "    Y_Train = np.zeros((len(Y_TRAIN),5))\n",
    "    for i in range(len(Y_TRAIN)):\n",
    "        Y_Train[i,Y_TRAIN[i]] = 1\n",
    "\n",
    "    Y_Test = np.zeros((len(Y_TEST),5))\n",
    "    for j in range(len(Y_TEST)):\n",
    "        Y_Test[j,Y_TEST[j]] = 1\n",
    "    XX_train = X_TRAIN.astype('float32') / 255.\n",
    "    XX_test = X_TEST.astype('float32') / 255.\n",
    "    XX_train = XX_train.T\n",
    "    XX_test =XX_test.T\n",
    "    Y_train = Y_Train.T\n",
    "    Y_test = Y_Test.T\n",
    "    regressor =  ANN_perceptron()\n",
    "    layers_dims = [XX_train.shape[0], 256, 64,32,5]\n",
    "    print(len(layers_dims))\n",
    "    par, costs = regressor.deep_layer_model(XX_train, Y_train, layers_dims, learning_rate=0.1, num_iterations=1000)\n",
    "    plt.plot(range(len(costs)),costs)\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.title(\"Costs vs iterations\")\n",
    "    print(\"Confusion Matrix: \",regressor.predict(par, XX_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Cost after iteration 0: 1.620998\n",
      "Cost after iteration 100: 0.135890\n",
      "Cost after iteration 200: 0.103918\n",
      "Cost after iteration 300: 0.088841\n",
      "Cost after iteration 400: 0.078111\n",
      "Cost after iteration 500: 0.069255\n",
      "Cost after iteration 600: 0.061610\n",
      "Cost after iteration 700: 0.054896\n",
      "Cost after iteration 800: 0.048953\n",
      "Cost after iteration 900: 0.043698\n",
      "label precision recall\n",
      "    0     0.992  0.996\n",
      "    1     0.996  0.994\n",
      "    2     0.979  0.972\n",
      "    3     0.988  0.989\n",
      "    4     0.987  0.991\n",
      "Test Accuracy:  0.9883245767659078\n",
      "Confusion Matrix:  [[9.760e+02 0.000e+00 2.000e+00 1.000e+00 1.000e+00]\n",
      " [1.000e+00 1.128e+03 6.000e+00 0.000e+00 0.000e+00]\n",
      " [6.000e+00 5.000e+00 1.003e+03 1.000e+01 8.000e+00]\n",
      " [0.000e+00 0.000e+00 7.000e+00 9.990e+02 4.000e+00]\n",
      " [1.000e+00 0.000e+00 7.000e+00 1.000e+00 9.730e+02]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
